{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97ee8a43",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#  MLOps Manual to Repeatable Workflow\n",
    "\n",
    "<div class=\"alert alert-warning\"> \n",
    "\t⚠️ <strong> PRE-REQUISITE: </strong> Before proceeding with this notebook, please ensure that you have executed the <code>1-data-prep-feature-store.ipynb</code> Notebook</li>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3ef1bc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Contents\n",
    "\n",
    "- [Introduction](#Introduction)\n",
    "- [Recap](#Recap)\n",
    "- [Experiment tracking](#Experiment-tracking)\n",
    "- [SageMaker Training](#SageMaker-Training)\n",
    "- [SageMaker Training with Automatic Model Tuning (HPO)](#SageMaker-Training-with-Automatic-Model-Tuning-(HPO))\n",
    "- [Model Registry](#Model-Registry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49b5eb2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "This is our second notebook which will explore the model training stage of the ML workflow.\n",
    "\n",
    "Here, we will put on the hat of the `Data Scientist` and will perform the task of modeling which includes training a model, performing hyperparameter tuning, and registering our model in a model registry. This task is highly iterative in nature and hence we need to track our experimentation until we reach desired results.\n",
    "\n",
    "Similar to previous notebook on preprocessing datasets, we will first start by performing the above tasks manually inside our notebook's local environment, using the local data generated during the previous steps. Then we will learn how to bring scale and experiment tracking into these steps using managed SageMaker training capabilities and how to connect it to SageMaker Feature Store.\n",
    "\n",
    "Let's get started!\n",
    "\n",
    "**Important:** for this example, we will use SageMaker's (XGBoost algorithm)[https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html] as a built-in model. That means that you don't have to write your model code and SageMaker takes care of it. We will use CSV data as input. For CSV training, the algorithm assumes that the target variable is in the first column and that the CSV does not have a header record. Let's query our Feature Store Group to get the necessary data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2de56a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e493d63",
   "metadata": {},
   "source": [
    "Let's first install the sagemaker-experiments library in case it is not yet installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4491bcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da618a1a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install sagemaker-experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629a43ad",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "from time import gmtime, strftime\n",
    "import boto3\n",
    "import sys\n",
    "import sagemaker\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from sagemaker.model_metrics import ModelMetrics, MetricsSource\n",
    "from sagemaker.analytics import ExperimentAnalytics\n",
    "from sagemaker.tuner import IntegerParameter, ContinuousParameter, HyperparameterTuner\n",
    "# SageMaker Experiments objects\n",
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "from sagemaker import image_uris\n",
    "from sagemaker.inputs import TrainingInput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf525dbb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Session variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279da59d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Useful SageMaker variables\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "role_arn= sagemaker.get_execution_role()\n",
    "region = sagemaker_session.boto_region_name\n",
    "s3_client = boto3.client('s3', region_name=region)\n",
    "sagemaker_client = boto3.client('sagemaker')\n",
    "\n",
    "enable_local_mode_training = False\n",
    "model_package_group_name = 'synthetic-housing-models'\n",
    "model_name = 'xgboost-model'\n",
    "\n",
    "\n",
    "fs_dir = os.path.join(os.getcwd(), 'data/fs_data')\n",
    "os.makedirs(fs_dir, exist_ok=True)\n",
    "\n",
    "fs_train_dir = os.path.join(os.getcwd(), 'data/fs_data/train')\n",
    "os.makedirs(fs_train_dir, exist_ok=True)\n",
    "\n",
    "fs_validation_dir = os.path.join(os.getcwd(), 'data/fs_data/validation')\n",
    "os.makedirs(fs_validation_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72d1641",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Recap\n",
    "\n",
    "So we've processed our data and now have training and validation sets available in Feature Store to be used for training. Since SageMaker training jobs expects the training data to be on s3, let's first add our feature store data to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc32606d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def save_fs_data_to_s3(fg_name, features_to_select, sm_session, file_name, local_path, bucket, bucket_prefix):\n",
    "    fs_group = FeatureGroup(name=fg_name, sagemaker_session=sm_session)  \n",
    "    query = fs_group.athena_query()\n",
    "    table = query.table_name\n",
    "    query_string = f'SELECT {features_to_select} FROM \"sagemaker_featurestore\".\"{table}\"  ORDER BY record_id'\n",
    "    query_results= 'sagemaker-featurestore'\n",
    "    output_location = f's3://{bucket}/{query_results}/query_results/'\n",
    "    query.run(query_string=query_string, output_location=output_location)\n",
    "    query.wait()\n",
    "    df = query.as_dataframe()\n",
    "    df.to_csv(local_path+'/'+file_name, index=False, header=False)\n",
    "    s3_client.upload_file(local_path+'/'+file_name, bucket, bucket_prefix+'/'+file_name)\n",
    "    dataset_uri_prefix = \"s3://\" + bucket + \"/\" + bucket_prefix\n",
    "    return dataset_uri_prefix\n",
    "\n",
    "train_data = save_fs_data_to_s3(\n",
    "    train_feature_group_name, \n",
    "    features_to_select, \n",
    "    sagemaker_session, \n",
    "    \"train.csv\", \n",
    "    fs_train_dir, \n",
    "    bucket, \n",
    "    s3_prefix+\"/data/fs_data/train\"\n",
    ")\n",
    "val_data = save_fs_data_to_s3(\n",
    "    validation_feature_group_name, \n",
    "    features_to_select, \n",
    "    sagemaker_session, \n",
    "    \"validation.csv\", \n",
    "    fs_validation_dir, \n",
    "    bucket, \n",
    "    s3_prefix+\"/data/fs_data/validation\"\n",
    ")\n",
    "train_data, val_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e2e28d",
   "metadata": {},
   "source": [
    "Let's compare the dataset distribution of our original dataset and the one read from Feature Store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da5adba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read original training data\n",
    "df_train_orig = pd.read_csv(sm_processed_train_dir+'/train.csv', header=None)\n",
    "df_train_orig.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7e54b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading training data from Feature Store\n",
    "df_train_fs = pd.read_csv(fs_train_dir+'/train.csv', header=None)\n",
    "df_train_fs.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989eacb9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Great! Our dataset distribution seems intact!.\n",
    "\n",
    "We are ready to train a SageMaker Built-in XGboost model with it!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2092f66e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Ok, let's run the above script on our local notebook resources and make sure everything's working alright."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c851ec",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Experiment tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb53b0dc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "[SageMaker Experiments](https://docs.aws.amazon.com/sagemaker/latest/dg/experiments.html) can track all the model training iterations. Experiments are a great way to organize your data science work. You can create experiments to organize all your model development work for:\n",
    "\n",
    "1. A business use case you are addressing (e.g. create experiment named \"customer churn prediction\"), or\n",
    "2. A data science team that owns the experiment (e.g. create experiment named \"marketing analytics experiment\"), or\n",
    "3. A specific data science and ML project. Think of it as a \"folder\" for organizing your \"files\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def4cbd5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "synthetic_housing_experiment = Experiment.create(\n",
    "    experiment_name=f'synthetic-housing-xgboost-{strftime(\"%d-%H-%M-%S\", gmtime())}', \n",
    "    description='Synthetic housing price estimation.',\n",
    "    sagemaker_boto_client=sagemaker_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af016e38",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## SageMaker Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53ae83f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now that we've prepared our training and test data, we can move on to use SageMaker's hosted training functionality - [SageMaker Training](https://docs.aws.amazon.com/sagemaker/latest/dg/train-model.html). Hosted training is preferred for doing actual training, especially large-scale, distributed training. Unlike training a model on a local computer or server, SageMaker hosted training will spin up a separate cluster of machines managed by SageMaker to train your model. Before starting hosted training, the data must be in S3, or an EFS or FSx for Lustre file system. We uploaded to S3 in the previous notebook, so we're good to go here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856fee14",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's go ahead and create a built-in XGBoost model. You can see that we use the `Estimator` object with the xgboost container and all we need to do is pass the parameters to the model. SageMaker takes care of the implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fade9961",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# initialize hyperparameters\n",
    "hyperparameters = {\n",
    "    \"max_depth\": \"5\",\n",
    "    \"eta\": \"0.2\",\n",
    "    \"gamma\": \"4\",\n",
    "    \"min_child_weight\": \"6\",\n",
    "    \"subsample\": \"0.7\",\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"num_round\": \"50\",\n",
    "    \"verbosity\": \"2\",\n",
    "    \"eval_metric\": \"mse\"\n",
    "}\n",
    "\n",
    "train_instance_type = 'ml.c5.xlarge'\n",
    "\n",
    "train_input = TrainingInput(train_data, content_type='text/csv')\n",
    "validation_input = TrainingInput(val_data, content_type='text/csv')\n",
    "inputs = {'train': train_input, 'validation': validation_input}\n",
    "\n",
    "# this line automatically looks for the XGBoost image URI and builds an XGBoost container.\n",
    "# specify the repo_version depending on your preference.\n",
    "xgboost_container = sagemaker.image_uris.retrieve(\"xgboost\", region, \"1.5-1\")\n",
    "\n",
    "# construct a SageMaker estimator that calls the xgboost-container\n",
    "estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri=xgboost_container, \n",
    "    hyperparameters=hyperparameters,\n",
    "    role=role_arn,\n",
    "    instance_count=1, \n",
    "    instance_type='ml.m5.2xlarge', \n",
    "    volume_size=5, # 5 GB \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d2337e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Before we actually train the `XGBoost` model, we'll create a trial under the experiment we created at the beginning of this notebook. The results of the training job we're about to run will be tracked by SageMaker Experiments under this trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57f04dc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "regresor_trial = Trial.create(\n",
    "    trial_name = f'xgboost-{strftime(\"%d-%H-%M-%S\", gmtime())}',\n",
    "    experiment_name = synthetic_housing_experiment.experiment_name\n",
    ")\n",
    "\n",
    "experiment_config = {\n",
    "    'ExperimentName': synthetic_housing_experiment.experiment_name,\n",
    "    'TrialName': regresor_trial.trial_name,\n",
    "    'TrialComponentDisplayName': 'TrainingJob',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66492dd1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now that we've passed in the necessary inputs to the `Estimator` object, we can now call its `fit` method in order to train the xgboost model on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41d802d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "estimator.fit(inputs, experiment_config=experiment_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93fbfab",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now that training finished, we can use SageMaker Experiments to examine the results and see how it compares to other training jobs within the experiment. Right now this is the only job captured in Experiments, but let's take a look anyway to see what data it stores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9adcc30",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trial_component_analytics = ExperimentAnalytics(\n",
    "    sagemaker_session=sagemaker_session, \n",
    "    experiment_name=synthetic_housing_experiment.experiment_name,\n",
    "    sort_order=\"Descending\"\n",
    ")\n",
    "\n",
    "df_experiments = trial_component_analytics.dataframe()\n",
    "df_experiments[[\n",
    "    'Trials', 'TrialComponentName', 'DisplayName', 'train:mse - Avg', 'validation:mse - Avg', \n",
    "    'max_depth', 'eta', 'gamma', 'min_child_weight', 'subsample', 'objective', 'num_round', \n",
    "    'verbosity','SourceArn'\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ca430c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Well, that MSE looks quite good, but in cases where it's undesirable, we could improve it by adjusting model hyperparameters. But instead of guessing what hyperparameters we should have, we can let SageMaker search the hyperparameter space in an intelligent way on our behalf."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143c8b41",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## SageMaker Training with Automatic Model Tuning (HPO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678aa910",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "[Amazon SageMaker Automatic Model Tuning](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning.html), also known as hyperparameter tuning/optimization, finds the best version of a model by running many training jobs on your dataset using the algorithm and ranges of hyperparameters that you specify. It then chooses the hyperparameter values that result in a model that performs the best, as measured by a metric that you choose.\n",
    "\n",
    "You can use SageMaker automatic model tuning with built-in algorithms, custom algorithms, and SageMaker pre-built containers for machine learning frameworks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe599dd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We begin by specifying the hyperparameters we wish to tune, and the range of values over which to tune each one.  We also must specify an objective metric to be optimized:  in this use case, we'd like to minimize the validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bd7d44",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {\n",
    "  'max_depth': IntegerParameter(1, 10),\n",
    "  'alpha': ContinuousParameter(0, 1000),\n",
    "  'gamma': ContinuousParameter(0, 5),\n",
    "}\n",
    "\n",
    "objective_metric_name = 'validation:mse'\n",
    "objective_type = 'Minimize'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efce7e0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next we specify a HyperparameterTuner object that takes the above definitions as parameters.  Each tuning job must be given a budget:  a maximum number of training jobs.  A tuning job will complete after that many training jobs have been executed.  \n",
    "\n",
    "We also can specify how much parallelism to employ, in this case two jobs, meaning that the tuning job will complete after two series of two jobs in parallel have completed (so, a total of 4 jobs as set by `max_jobs`).  For the default Bayesian Optimization tuning strategy used here, the tuning search is informed by the results of previous groups of training jobs, so we don't run all of the jobs in parallel, but rather divide the jobs into groups of parallel jobs.  There is a trade-off: using more parallel jobs will finish tuning sooner, but likely will sacrifice tuning search accuracy. \n",
    "\n",
    "Now we can launch a hyperparameter tuning job by calling the `fit` method of the HyperparameterTuner object.  The tuning job may take some minutes to finish.  While you're waiting, the status of the tuning job, including metadata and results for invidual training jobs within the tuning job, can be checked in the SageMaker console in the **Hyperparameter tuning jobs** panel.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7a43ac",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tuner_parameters = {\n",
    "    'estimator': estimator,\n",
    "    'objective_metric_name': objective_metric_name,\n",
    "    'hyperparameter_ranges': hyperparameter_ranges,\n",
    "    'max_jobs': 4,\n",
    "    'max_parallel_jobs': 2,\n",
    "    'objective_type': objective_type\n",
    "}\n",
    "\n",
    "tuner = HyperparameterTuner(**tuner_parameters)\n",
    "\n",
    "tuning_job_name = f'xboost-model-tuning-{strftime(\"%d-%H-%M-%S\", gmtime())}'\n",
    "tuner.fit(inputs, job_name=tuning_job_name)\n",
    "tuner.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30750505",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "After the tuning job is finished, we can use the `HyperparameterTuningJobAnalytics` object from the SageMaker Python SDK to list the top 5 tuning jobs with the best performance. Although the results vary from tuning job to tuning job, the best validation loss from the tuning job (under the FinalObjectiveValue column) likely will be substantially lower than the validation loss from the hosted training job above, where we did not perform any tuning other than manually increasing the number of epochs once.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12865b0e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tuner_metrics = sagemaker.HyperparameterTuningJobAnalytics(tuning_job_name)\n",
    "tuner_metrics.dataframe().sort_values(['FinalObjectiveValue'], ascending=True).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572486b9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model Registry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608dda7f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "With the [SageMaker Model Registry](https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry.html) you can do the following:\n",
    "\n",
    "- Catalog models for production.\n",
    "- Manage model versions.\n",
    "- Associate metadata, such as training metrics, with a model.\n",
    "- Manage the approval status of a model.\n",
    "- Deploy models to production.\n",
    "- Automate model deployment with CI/CD.\n",
    "\n",
    "You can catalog models by creating model package groups that contain different versions of a model. You can create a model group that tracks all of the models that you train to solve a particular problem. You can then register each model you train and the model registry adds it to the model group as a new model version. A typical workflow might look like the following:\n",
    "\n",
    "- Create a model group.\n",
    "- Create an ML pipeline that trains a model.\n",
    "- For each run of the ML pipeline, create a model version that you register in the model group you created in the first step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebd02ed",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "So first we'll create a [Model Package Group](https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry-model-group.html) in which we can store/group all related models and their versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d7611b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_model_package_group(model_package_group_name, model_package_group_description, sagemaker_session):\n",
    "    sagemaker_client = sagemaker_session.sagemaker_client\n",
    "\n",
    "    # Check if model package group already exists\n",
    "    model_package_group_exists = False\n",
    "    model_package_groups = sagemaker_client.list_model_package_groups(NameContains=model_package_group_name)\n",
    "    for list_item in model_package_groups['ModelPackageGroupSummaryList']:\n",
    "        if list_item['ModelPackageGroupName'] == model_package_group_name:\n",
    "            model_package_group_exists = True\n",
    "\n",
    "    # Create new model package group if it doesn't already exist\n",
    "    if model_package_group_exists != True:\n",
    "        sagemaker_client.create_model_package_group(ModelPackageGroupName=model_package_group_name,\n",
    "                                                  ModelPackageGroupDescription=model_package_group_description)\n",
    "    else:\n",
    "        print(f'{model_package_group_name} Model Package Group already exists')\n",
    "\n",
    "create_model_package_group(model_package_group_name, 'Models predicting synthetic housing prices',\n",
    "                           sagemaker_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de0cd93",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next we'll register the model we just trained with SageMaker Training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6911dab0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_training_job_metrics(estimator, s3_prefix, region, bucket, problem_type='regression'):\n",
    "    # Define supervised learning problem type\n",
    "    if problem_type == 'regression':\n",
    "        model_metrics_report = {'regression_metrics': {}}\n",
    "    elif problem_type == 'classification':\n",
    "        model_metrics_report = {'classification_metrics': {}}\n",
    "    \n",
    "    # Parse training job metrics defined in metric_definitions\n",
    "    training_job_info = estimator.latest_training_job.describe()\n",
    "    training_job_name = training_job_info['TrainingJobName']\n",
    "    metrics = training_job_info['FinalMetricDataList']\n",
    "    for metric in metrics:\n",
    "        metric_dict = {metric['MetricName']: {'value': metric['Value'], 'standard_deviation': 'NaN'}}\n",
    "        if problem_type == 'regression':\n",
    "            model_metrics_report['regression_metrics'].update(metric_dict)\n",
    "        if problem_type == 'classification':\n",
    "            model_metrics_report['classification_metrics'].update(metric_dict)\n",
    "            \n",
    "    with open('training_metrics.json', 'w') as f:\n",
    "        json.dump(model_metrics_report, f)\n",
    "    \n",
    "    training_metrics_s3_prefix = f'{s3_prefix}/training_jobs/{training_job_name}/training_metrics.json'\n",
    "    s3_client = boto3.client('s3', region_name=region)\n",
    "    s3_client.upload_file(Filename='training_metrics.json', Bucket=bucket, Key=training_metrics_s3_prefix)\n",
    "    training_metrics_s3_uri = f's3://{bucket}/{training_metrics_s3_prefix}'\n",
    "    model_statistics = MetricsSource('application/json', training_metrics_s3_uri)\n",
    "    model_metrics = ModelMetrics(model_statistics=model_statistics)\n",
    "    return model_metrics\n",
    "\n",
    "# Register model\n",
    "best_estimator = tuner.best_estimator()\n",
    "model_metrics = create_training_job_metrics(best_estimator, s3_prefix, region, bucket)\n",
    "\n",
    "model_package = best_estimator.register(content_types=['text/csv'],\n",
    "                                        response_types=['application/json'],\n",
    "                                        inference_instances=['ml.m5.xlarge'],\n",
    "                                        transform_instances=['ml.m5.xlarge'],\n",
    "                                        image_uri=best_estimator.image_uri,\n",
    "                                        model_package_group_name=model_package_group_name,\n",
    "                                        model_metrics=model_metrics,\n",
    "                                        approval_status='PendingManualApproval',\n",
    "                                        description='XGBoost model to predict synthetic housing prices',\n",
    "                                        model_name=model_name,\n",
    "                                        name=model_name)\n",
    "model_package_arn = model_package.model_package_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d60b072",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We'll store relevant variables to be used in the next notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ef883c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%store model_package_arn\n",
    "%store model_name\n",
    "%store model_package_group_name\n",
    "%store model_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6738036",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
