{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4951298",
   "metadata": {},
   "source": [
    "#  MLOps Manual to Repeatable Workflow\n",
    "\n",
    "<div class=\"alert alert-warning\"> \n",
    "\t⚠️ <strong> PRE-REQUISITE: </strong> Before proceeding with this notebook, please ensure that you have executed the <code>1-data-prep-feature-store.ipynb</code> and <code>2-training-registry.ipynb</code> Notebooks</li>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfbe6eb",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "- [Introduction](#Introduction)\n",
    "- [SageMaker Endpoint](#SageMaker-Endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a98def2",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a257cefa",
   "metadata": {},
   "source": [
    "This is our third notebook which will explore the model deployment of ML workflow.\n",
    "\n",
    "Here, we will put on the hat of a `Data Scientist` and will perform the task of model deployment which includes fetching the right model and deploying it for inference.  \n",
    "\n",
    "For this task we will be using Amazon SageMaker Model Hosting capabilities.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41947de1",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae19c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22c1dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "import io\n",
    "from sagemaker.model import ModelPackage\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "import numpy as np\n",
    "import pathlib\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11961781",
   "metadata": {},
   "source": [
    "**Session variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfbcdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful SageMaker variables\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "role_arn= sagemaker.get_execution_role()\n",
    "region = sagemaker_session.boto_region_name\n",
    "s3_client = boto3.client('s3', region_name=region)\n",
    "sagemaker_client = boto3.client('sagemaker')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf97a72",
   "metadata": {},
   "source": [
    "## SageMaker Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7e0311",
   "metadata": {},
   "source": [
    "You can also deploy your trained model as [SageMaker hosted endpoint](https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints-deployment.html) which serves real-time predictions from a trained model. The endpoint will retrieve the model created during training and deploy it within a SageMaker scikit-learn container. This all can be accomplished with one line of code. Note that it will take several minutes to deploy the model to a hosted endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec73129",
   "metadata": {},
   "source": [
    "Let's get the model we registered in the Model Registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dc5b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_regressor_model = ModelPackage(\n",
    "    role_arn,\n",
    "    model_package_arn=model_package_arn,\n",
    "    name=model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48950b6",
   "metadata": {},
   "source": [
    "It's current status is `PendingApproval`. In order to use this model for offline predictions or as a real-time endpoint, we'll need to update its status to `Approved`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f59cda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_client.update_model_package(\n",
    "    ModelPackageArn=xgboost_regressor_model.model_package_arn,\n",
    "    ModelApprovalStatus='Approved'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63cd197",
   "metadata": {},
   "source": [
    "Now we can deploy it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111cc788",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_regressor_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    endpoint_name=f'{model_name}-endpoint'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca391a2",
   "metadata": {},
   "source": [
    "Let's test this real-time endpoint by passing it some data and getting a real-time prediction back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f9a445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in test set that was used for batch transform\n",
    "fs_group = FeatureGroup(name=test_feature_group_name, sagemaker_session=sagemaker_session)  \n",
    "query = fs_group.athena_query()\n",
    "table = query.table_name\n",
    "query_string = f'SELECT {features_to_select} FROM \"sagemaker_featurestore\".\"{table}\"  ORDER BY record_id'\n",
    "query_results= 'sagemaker-featurestore'\n",
    "output_location = f's3://{bucket}/{query_results}/query_results/'\n",
    "query.run(query_string=query_string, output_location=output_location)\n",
    "query.wait()\n",
    "df = query.as_dataframe()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e6efd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach to the SageMaker endpoint\n",
    "predictor = Predictor(endpoint_name=f'{model_name}-endpoint',\n",
    "                      sagemaker_session=sagemaker_session,\n",
    "                      serializer=CSVSerializer(),\n",
    "                      deserializer=JSONDeserializer())\n",
    "\n",
    "# Get a real-time prediction\n",
    "predictor.predict(df.drop(columns=[\"price\"]).to_csv(index=False, header=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca9f7ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad32a0b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
